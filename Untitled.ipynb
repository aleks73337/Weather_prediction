{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepair_data(path):\n",
    "    data = pd.read_csv(path, sep=\",\")\n",
    "    data = data.drop(\"TAVG\", axis = 1)\n",
    "    data.dropna(inplace=True)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    mounths = []\n",
    "    New_york = []\n",
    "    Los_Angeles = []\n",
    "\n",
    "\n",
    "    Winter = []\n",
    "    Spring = []\n",
    "    Summer = []\n",
    "    Fall = []\n",
    "    for i in range(data.shape[0]):\n",
    "        month = re.search(\"-..-\", data.iloc[i][\"DATE\"])[0]\n",
    "        month = month.replace('-','')\n",
    "        month_int = int(month)\n",
    "    #     print(month_int)\n",
    "        if ((month_int == 1) | (month_int == 2) | (month_int == 12)):\n",
    "            Winter.append(1)\n",
    "            Spring.append(0)\n",
    "            Summer.append(0)\n",
    "            Fall.append(0)\n",
    "        elif ((month_int >= 3) & (month_int <= 5)):\n",
    "            Winter.append(0)\n",
    "            Spring.append(1)\n",
    "            Summer.append(0)\n",
    "            Fall.append(0)\n",
    "        elif ((month_int >= 6) & (month_int <= 8)):\n",
    "            Winter.append(0)\n",
    "            Spring.append(0)\n",
    "            Summer.append(1)\n",
    "            Fall.append(0)\n",
    "        elif ((month_int >= 9) & (month_int <= 11)):\n",
    "            Winter.append(0)\n",
    "            Spring.append(0)\n",
    "            Summer.append(0)\n",
    "            Fall.append(1)\n",
    "        month_int = (month_int) % 3\n",
    "        mounths.append(month_int)\n",
    "        if (data.iloc[i][\"NAME\"] == \"BURBANK GLENDALE PASADENA AIRPORT, CA US\"):\n",
    "            Los_Angeles.append(1)\n",
    "            New_york.append(0)\n",
    "        else:\n",
    "            New_york.append(1)\n",
    "            Los_Angeles.append(0)\n",
    "        \n",
    "    data = data.drop(\"DATE\", axis = 1)\n",
    "    data = data.drop(\"STATION\", axis = 1)\n",
    "    data = data.drop(\"NAME\", axis = 1)\n",
    "    # data.insert(0, column = \"MOSCOW\", value = Moskow)\n",
    "    # data.insert(0, column = \"VLADIMIR\", value = Vladimir)\n",
    "    data.insert(0, column = \"NEW YORK\", value = New_york)\n",
    "    data.insert(0, column = \"LOS ANGELES\", value = Los_Angeles)\n",
    "    data.insert(0, column = \"WINTER\", value = Winter)\n",
    "    data.insert(0, column = \"SPRING\", value = Spring)\n",
    "    data.insert(0, column = \"SUMMER\", value = Summer)\n",
    "    data.insert(0, column = \"FALL\", value= Fall)\n",
    "    data.insert(0, column = \"MONTH\", value = mounths)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# print(data)\n",
    "#data = data.loc[:,\"DATE\":\"TMIN\"]\n",
    "#data = data.drop(\"SNWD\", axis=1)\n",
    "#data = data.drop(\"PRCP\", axis=1)\n",
    "# data = data.dropna(). reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepair_data(\"New_York.csv\")\n",
    "data, norm = normalize(data, norm='l2', return_norm = True, axis = 0)\n",
    "train_x = data[0:(data.shape[0]-1)]\n",
    "train_y = data[1:data.shape[0], 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = prepair_data(\"New_York_test.csv\")\n",
    "test_data, test_norm = normalize(test_data, norm='l2', return_norm = True, axis = 0)\n",
    "test_x = test_data[0: test_data.shape[0] - 1]\n",
    "test_y = test_data[1: test_data.shape[0], 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_data = prepair_data(\"LA_train.csv\")\n",
    "la_train, la_norm =  normalize(LA_data, norm='l2', return_norm = True, axis = 0)\n",
    "la_train_x = la_train[0: la_train.shape[0] - 1]\n",
    "la_train_y = la_train[1: la_train.shape[0], 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.concatenate((train_x, la_train_x))\n",
    "train_y = np.concatenate((train_y, la_train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_test_data = prepair_data(\"LA_test.csv\")\n",
    "la_test, la_test_norm =  normalize(LA_test_data, norm='l2', return_norm = True, axis = 0)\n",
    "la_test_x = la_test[0: la_test.shape[0] - 1]\n",
    "la_test_y = la_test[1: la_test.shape[0], 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = np.concatenate((test_x, la_test_x))\n",
    "test_y = np.concatenate((test_y, la_test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.losses import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_keras(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(172, 10)\n"
     ]
    }
   ],
   "source": [
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                352       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 11,297\n",
      "Trainable params: 11,105\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()  \n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_shape = (train_x.shape[1],)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(64))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='nadam', loss=[mean_squared_error], metrics=[r2_keras])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13839 samples, validate on 172 samples\n",
      "Epoch 1/50\n",
      "13839/13839 [==============================] - 1s 68us/step - loss: 5.9706e-06 - r2_keras: 0.7226 - val_loss: 0.0027 - val_r2_keras: -0.2204\n",
      "Epoch 2/50\n",
      "13839/13839 [==============================] - 1s 67us/step - loss: 6.0376e-06 - r2_keras: 0.7187 - val_loss: 0.0027 - val_r2_keras: 0.0397\n",
      "Epoch 3/50\n",
      "13839/13839 [==============================] - 1s 64us/step - loss: 5.8162e-06 - r2_keras: 0.7298 - val_loss: 0.0030 - val_r2_keras: -0.7054\n",
      "Epoch 4/50\n",
      "13839/13839 [==============================] - 1s 65us/step - loss: 5.8456e-06 - r2_keras: 0.7274 - val_loss: 0.0026 - val_r2_keras: -0.0072\n",
      "Epoch 5/50\n",
      "13839/13839 [==============================] - 1s 65us/step - loss: 5.8843e-06 - r2_keras: 0.7287 - val_loss: 0.0031 - val_r2_keras: -0.7544\n",
      "Epoch 6/50\n",
      "13839/13839 [==============================] - 1s 66us/step - loss: 5.8553e-06 - r2_keras: 0.7314 - val_loss: 0.0031 - val_r2_keras: -0.8229\n",
      "Epoch 7/50\n",
      "13839/13839 [==============================] - 1s 64us/step - loss: 5.8924e-06 - r2_keras: 0.7255 - val_loss: 0.0026 - val_r2_keras: -0.0298\n",
      "Epoch 8/50\n",
      "13839/13839 [==============================] - 1s 64us/step - loss: 5.6904e-06 - r2_keras: 0.7370 - val_loss: 0.0026 - val_r2_keras: 0.0935\n",
      "Epoch 9/50\n",
      "13839/13839 [==============================] - 1s 65us/step - loss: 5.8758e-06 - r2_keras: 0.7286 - val_loss: 0.0029 - val_r2_keras: -0.5457\n",
      "Epoch 10/50\n",
      "13839/13839 [==============================] - 1s 65us/step - loss: 5.8249e-06 - r2_keras: 0.7285 - val_loss: 0.0027 - val_r2_keras: -0.1747\n",
      "Epoch 11/50\n",
      "13839/13839 [==============================] - 1s 65us/step - loss: 5.9127e-06 - r2_keras: 0.7223 - val_loss: 0.0027 - val_r2_keras: -0.1967\n",
      "Epoch 12/50\n",
      "13839/13839 [==============================] - 1s 66us/step - loss: 5.8171e-06 - r2_keras: 0.7307 - val_loss: 0.0028 - val_r2_keras: -0.2769\n",
      "Epoch 13/50\n",
      "13839/13839 [==============================] - 1s 67us/step - loss: 5.7037e-06 - r2_keras: 0.7382 - val_loss: 0.0026 - val_r2_keras: -0.0302\n",
      "Epoch 14/50\n",
      "13839/13839 [==============================] - 1s 82us/step - loss: 5.8641e-06 - r2_keras: 0.7242 - val_loss: 0.0027 - val_r2_keras: -0.2898\n",
      "Epoch 15/50\n",
      "13839/13839 [==============================] - 1s 67us/step - loss: 5.5940e-06 - r2_keras: 0.7431 - val_loss: 0.0027 - val_r2_keras: -0.1179\n",
      "Epoch 16/50\n",
      "13839/13839 [==============================] - 1s 65us/step - loss: 5.7380e-06 - r2_keras: 0.7309 - val_loss: 0.0028 - val_r2_keras: -0.2870\n",
      "Epoch 17/50\n",
      "13839/13839 [==============================] - 1s 65us/step - loss: 5.7310e-06 - r2_keras: 0.7315 - val_loss: 0.0027 - val_r2_keras: -0.3863\n",
      "Epoch 18/50\n",
      "13839/13839 [==============================] - 1s 67us/step - loss: 5.7293e-06 - r2_keras: 0.7310 - val_loss: 0.0026 - val_r2_keras: -0.1623\n",
      "Epoch 19/50\n",
      "13839/13839 [==============================] - 1s 65us/step - loss: 5.7202e-06 - r2_keras: 0.7363 - val_loss: 0.0027 - val_r2_keras: -0.2049\n",
      "Epoch 20/50\n",
      "13839/13839 [==============================] - 1s 65us/step - loss: 5.6508e-06 - r2_keras: 0.7379 - val_loss: 0.0026 - val_r2_keras: -0.0306\n",
      "Epoch 21/50\n",
      "13839/13839 [==============================] - 1s 65us/step - loss: 5.6636e-06 - r2_keras: 0.7386 - val_loss: 0.0028 - val_r2_keras: -0.2638\n",
      "Epoch 22/50\n",
      "13839/13839 [==============================] - 1s 65us/step - loss: 5.8071e-06 - r2_keras: 0.7306 - val_loss: 0.0029 - val_r2_keras: -0.6118\n",
      "Epoch 23/50\n",
      "13839/13839 [==============================] - 1s 66us/step - loss: 5.6521e-06 - r2_keras: 0.7368 - val_loss: 0.0028 - val_r2_keras: -0.4018\n",
      "Epoch 24/50\n",
      "13839/13839 [==============================] - 1s 66us/step - loss: 5.6655e-06 - r2_keras: 0.7348 - val_loss: 0.0027 - val_r2_keras: -0.2533\n",
      "Epoch 25/50\n",
      "13839/13839 [==============================] - 1s 66us/step - loss: 5.7309e-06 - r2_keras: 0.7320 - val_loss: 0.0027 - val_r2_keras: -0.1347\n",
      "Epoch 26/50\n",
      "13839/13839 [==============================] - 1s 67us/step - loss: 5.5472e-06 - r2_keras: 0.7448 - val_loss: 0.0027 - val_r2_keras: -0.1353\n",
      "Epoch 27/50\n",
      "13839/13839 [==============================] - 1s 65us/step - loss: 5.6049e-06 - r2_keras: 0.7419 - val_loss: 0.0028 - val_r2_keras: -0.4468\n",
      "Epoch 28/50\n",
      "13839/13839 [==============================] - 1s 65us/step - loss: 5.7134e-06 - r2_keras: 0.7314 - val_loss: 0.0032 - val_r2_keras: -1.0443\n",
      "Epoch 29/50\n",
      "13839/13839 [==============================] - 1s 75us/step - loss: 5.7848e-06 - r2_keras: 0.7292 - val_loss: 0.0027 - val_r2_keras: -0.1398\n",
      "Epoch 30/50\n",
      "13839/13839 [==============================] - 1s 70us/step - loss: 5.7180e-06 - r2_keras: 0.7318 - val_loss: 0.0026 - val_r2_keras: 0.0607\n",
      "Epoch 31/50\n",
      "13839/13839 [==============================] - 1s 65us/step - loss: 5.6322e-06 - r2_keras: 0.7394 - val_loss: 0.0027 - val_r2_keras: -0.2485\n",
      "Epoch 32/50\n",
      "13839/13839 [==============================] - 1s 66us/step - loss: 5.5688e-06 - r2_keras: 0.7416 - val_loss: 0.0028 - val_r2_keras: -0.3480\n",
      "Epoch 33/50\n",
      "13839/13839 [==============================] - 1s 69us/step - loss: 5.6797e-06 - r2_keras: 0.7374 - val_loss: 0.0033 - val_r2_keras: -1.1389\n",
      "Epoch 34/50\n",
      "13839/13839 [==============================] - 1s 65us/step - loss: 5.7324e-06 - r2_keras: 0.7328 - val_loss: 0.0026 - val_r2_keras: 0.0121\n",
      "Epoch 35/50\n",
      "13839/13839 [==============================] - 1s 66us/step - loss: 5.5460e-06 - r2_keras: 0.7437 - val_loss: 0.0028 - val_r2_keras: -0.4077\n",
      "Epoch 36/50\n",
      "13839/13839 [==============================] - 1s 66us/step - loss: 5.5732e-06 - r2_keras: 0.7394 - val_loss: 0.0027 - val_r2_keras: 0.0676\n",
      "Epoch 37/50\n",
      "13839/13839 [==============================] - 1s 67us/step - loss: 5.6489e-06 - r2_keras: 0.7397 - val_loss: 0.0027 - val_r2_keras: -0.1918\n",
      "Epoch 38/50\n",
      "13839/13839 [==============================] - 1s 66us/step - loss: 5.4865e-06 - r2_keras: 0.7473 - val_loss: 0.0031 - val_r2_keras: -0.9321\n",
      "Epoch 39/50\n",
      "13839/13839 [==============================] - 1s 71us/step - loss: 5.7862e-06 - r2_keras: 0.7334 - val_loss: 0.0027 - val_r2_keras: -0.1064\n",
      "Epoch 40/50\n",
      "13839/13839 [==============================] - 1s 71us/step - loss: 5.6828e-06 - r2_keras: 0.7383 - val_loss: 0.0027 - val_r2_keras: -0.2408\n",
      "Epoch 41/50\n",
      "13839/13839 [==============================] - 1s 73us/step - loss: 5.6670e-06 - r2_keras: 0.7314 - val_loss: 0.0028 - val_r2_keras: -0.3780\n",
      "Epoch 42/50\n",
      "13839/13839 [==============================] - 1s 74us/step - loss: 5.5763e-06 - r2_keras: 0.7405 - val_loss: 0.0028 - val_r2_keras: -0.4438\n",
      "Epoch 43/50\n",
      "13839/13839 [==============================] - 1s 71us/step - loss: 5.5273e-06 - r2_keras: 0.7460 - val_loss: 0.0026 - val_r2_keras: -0.0302\n",
      "Epoch 44/50\n",
      "13839/13839 [==============================] - 1s 67us/step - loss: 5.5309e-06 - r2_keras: 0.7443 - val_loss: 0.0029 - val_r2_keras: -0.5753\n",
      "Epoch 45/50\n",
      "13839/13839 [==============================] - 1s 66us/step - loss: 5.6358e-06 - r2_keras: 0.7334 - val_loss: 0.0030 - val_r2_keras: -0.6472\n",
      "Epoch 46/50\n",
      "13839/13839 [==============================] - 1s 65us/step - loss: 5.6212e-06 - r2_keras: 0.7383 - val_loss: 0.0026 - val_r2_keras: -0.0939\n",
      "Epoch 47/50\n",
      "13839/13839 [==============================] - 1s 65us/step - loss: 5.5794e-06 - r2_keras: 0.7394 - val_loss: 0.0026 - val_r2_keras: -0.1805\n",
      "Epoch 48/50\n",
      "13839/13839 [==============================] - 1s 66us/step - loss: 5.8379e-06 - r2_keras: 0.7282 - val_loss: 0.0032 - val_r2_keras: -1.0588\n",
      "Epoch 49/50\n",
      "13839/13839 [==============================] - 1s 65us/step - loss: 5.6859e-06 - r2_keras: 0.7357 - val_loss: 0.0026 - val_r2_keras: 0.0352\n",
      "Epoch 50/50\n",
      "13839/13839 [==============================] - 1s 68us/step - loss: 5.5069e-06 - r2_keras: 0.7438 - val_loss: 0.0027 - val_r2_keras: -0.0157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24c1130d6d8>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, batch_size = 32, epochs=50,  verbose=1, validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [10,0,1,1,0.00,33,34.0,29.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11.754062]]\n",
      "5.659500589657867\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(np.array([test_x[0]],))*la_test_norm[7])\n",
    "print(test_y[0]*la_test_norm[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
